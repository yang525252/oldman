<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>实时情绪检测</title>
  <!-- 引入 Human 库 -->
  <script src="https://cdn.jsdelivr.net/npm/@vladmandic/human/dist/human.js"></script>
  <style>
    /* 隐藏视频元素，但保持其功能 */
    #video {
    position: absolute;
  
  width: 1px;
  height: 1px;
    }
  </style>
</head>
<body>
  
  <!-- 视频元素用于显示摄像头画面 -->
  <video id="video" width="320" height="240" autoplay muted playsinline></video>
  <!-- 画布用于绘制检测结果 -->
  <canvas id="canvas" width="320" height="240"></canvas>
  <!-- 假设 iframe 的 id 是 'gradio_iframe' -->
<iframe id="gradio_iframe" src="https://yang5252-oldman2.hf.space" style="width:100%; height:600px;"></iframe>

<script>
// 在情绪检测代码中，当检测到情绪时：
function sendEmotionToGradio(emotion) {
  const iframe = document.getElementById('gradio_iframe');
  iframe.contentWindow.postMessage({ emotion: emotion }, 'https://yang5252-oldman2.hf.space');
}
</script>

  <script>
    // 配置 Human 库
    const humanConfig = {
      modelBasePath: 'https://cdn.jsdelivr.net/npm/@vladmandic/human/models',
      face: {
        enabled: true,
        detector: { enabled: true },
        mesh: { enabled: false },
        iris: { enabled: false },
        emotion: { enabled: true },
        description: { enabled: false },
        age: { enabled: false },
        gender: { enabled: false },
      },
    };

    const human = new Human.Human(humanConfig);

    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');

    let lastEmotion = '';
    let emotionTimestamp = 0;

    // 设置摄像头
    async function setupCamera() {
      const stream = await navigator.mediaDevices.getUserMedia({ video: true });
      video.srcObject = stream;
      return new Promise((resolve) => {
        video.onloadedmetadata = () => {
          resolve(video);
        };
      });
    }

    // 渲染函数，进行实时检测和绘制
    async function render() {
      const result = await human.detect(video);

      // 绘制摄像头画面
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

      // 绘制检测结果
      if (result.face && result.face.length > 0) {
        for (let face of result.face) {
          const { box, emotion } = face;
          // 绘制人脸边框
          ctx.strokeStyle = 'red';
          ctx.lineWidth = 2;
          ctx.strokeRect(box[0], box[1], box[2], box[3]);
          // 显示情绪文字
          if (emotion && emotion.length > 0) {
            const emotions = emotion.map((e) => `${e.emotion}: ${e.score.toFixed(2)}`).join(', ');
            lastEmotion = emotions;
            emotionTimestamp = Date.now();
            ctx.fillStyle = 'red';
            ctx.font = '16px Arial';
            ctx.fillText(emotions, box[0], box[1] - 10);
          }
        }
      }
      
      // 在画面上显示情绪文字，持续至少5秒
      if (lastEmotion && Date.now() - emotionTimestamp < 5000) {
        ctx.fillStyle = 'red';
        ctx.font = '16px Arial';
        ctx.fillText(lastEmotion, 10, 20);
      }

      requestAnimationFrame(render);
    }

    // 初始化函数
    (async () => {
      await human.load();
      await human.warmup(); // 可选，预加载模型以提高性能
      await setupCamera();
      render();
    })();
  </script>
</body>
</html>
